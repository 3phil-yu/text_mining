{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(co_list,col):\n",
    "    '''\n",
    "        rows: 所有用来构建合作网络的数据行\n",
    "        col: 作者信息所在列数-1\n",
    "    '''\n",
    "    nodes_list = []\n",
    "    for authors in co_list:\n",
    "        auths = authors[col].split(\" | \") # 分隔符可换\n",
    "        for auth in auths:\n",
    "            if auth not in nodes_list: # 去重\n",
    "                nodes_list.append(auth)\n",
    "    return nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(rows,name_list,col):\n",
    "    '''\n",
    "        rows: 形如co_list的所有用来构建合作网络的数据行\n",
    "        name_list: 出现的作者（节点）列表\n",
    "        col: 作者信息所在列数-1\n",
    "    '''\n",
    "\n",
    "    length = len(name_list)\n",
    "    cooperate_list = []\n",
    "    links = []\n",
    "    # 遍历作者名,计数和各作者合作数(每次合作对自己也计数)\n",
    "    for name in name_list:\n",
    "        author_co = []\n",
    "        author_co.append(name)\n",
    "    # 合作列表：初始化为长度为节点个数的全零列表[name,0,0,0,...,0,0]\n",
    "        for i in range(length):\n",
    "            author_co.append(0) \n",
    "    # 遍历所有数据行,对作者字段进行匹配\n",
    "        for row in rows:\n",
    "            names_row = row[col].split(\" | \") # 分隔符按数据结构选\n",
    "    # 对包含当前作者的数据项,提取合作关系(合作列表对应位置+1)\n",
    "            if name in names_row:\n",
    "                for the_name in names_row:\n",
    "                # 索引合作的作者编号,确定在合作列表中的位置\n",
    "                    name_num = name_list.index(the_name)+1 \n",
    "                # 对应位置+1\n",
    "                    author_co[name_num] = author_co[name_num] + 1 \n",
    "                # 获取边列表，作为提取“边-权重”列表和邻接表的输入\n",
    "                    if name!=the_name:\n",
    "                        link = sorted([name,the_name])\n",
    "                        links.append(link)\n",
    "    # 添加到合作矩阵列表中\n",
    "        cooperate_list.append(author_co)\n",
    "\n",
    "    # 1. 生成合作矩阵：csv_list\n",
    "    csv_list = []\n",
    "    first_line = []\n",
    "    first_line.append('')\n",
    "    first_line.extend(name_list)\n",
    "    csv_list.append(first_line) # 第一行,第一列为标题(出现的作者名)\n",
    "    csv_list.extend(cooperate_list)\n",
    "\n",
    "    # 2. 生成”边-权重“表csv_links\n",
    "    csv_links = get_weighted_links(links)\n",
    "    \n",
    "    # 3. 邻接表adj_links\n",
    "    adj_links  = get_adjacency(links)\n",
    "    #print(collections.Counter(adj_links))\n",
    "    b = tuple(tuple([y for y in x]) for x in adj_links)\n",
    "    print(collections.Counter(b))\n",
    "#     test=pd.DataFrame(data=csv_links)\n",
    "#     print(test)\n",
    "#     test.to_csv('testcsv.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_links(edges_list):\n",
    "    ''' edges_list：是包含边的列表,[[节点1,节点2],...],边可以重复,重复次数记为权重\n",
    "        返回值：带权重的边列表,[[节点1,节点2,weight],...]\n",
    "    '''\n",
    "    weighted_links = [] # 作为返回值\n",
    "    exist_links = [] # 记录当前已经出现过的边\n",
    "    for link in edges_list:\n",
    "        if link not in exist_links:\n",
    "            exist_links.append(link)\n",
    "            link.append(1) # 新边weight置1\n",
    "            weighted_links.append(link)            \n",
    "        else:\n",
    "            # exsit_links和weighted_links里的列表顺序是一样的\n",
    "            index = exist_links.index(link) \n",
    "            # 已存在的边,weight + 1\n",
    "            weighted_links[index][2] = weighted_links[index][2] + 1 \n",
    "    return weighted_links\n",
    "def get_adjacency(links):\n",
    "    ''' links：是包含边列表的矩阵,[[作者1,作者2],...],边可以重复,重复次数记为权重\n",
    "        返回值：邻接矩阵,[[作者1,作者2],...]\n",
    "    '''\n",
    "    adj_list = []\n",
    "    weighted_links = get_weighted_links(links)\n",
    "    for link in weighted_links:\n",
    "        num = int(link[2])\n",
    "        for i in range(num):\n",
    "            adj_list.append(link[:2])\n",
    "    \n",
    "    return adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('AA', 'CC'): 6, ('AA', 'DD'): 6, ('CC', 'DD'): 6, ('AA', 'BB'): 4, ('AA', 'GG'): 4, ('AA', 'FF'): 4, ('BB', 'EE'): 4, ('BB', 'FF '): 4, ('DD', 'LL'): 4, ('DD', 'GG'): 4, ('GG', 'HH'): 4, ('AA', 'HH'): 2, ('AA', 'KK'): 2, ('AA', 'LL'): 2, ('AA', 'FF '): 2, ('BB', 'CC'): 2, ('BB', 'DD'): 2, ('BB', 'GG '): 2, ('CC', 'FF'): 2, ('CC', 'LL'): 2, ('CC', 'GG'): 2, ('DD', 'FF'): 2, ('DD', 'HH'): 2, ('DD', 'EE'): 2, ('EE', 'FF '): 2, ('EE', 'GG '): 2, ('EE', 'GG'): 2, ('EE', 'LL'): 2, ('EE', 'HH'): 2, ('FF', 'GG'): 2, ('GG', 'KK'): 2, ('GG', 'LL'): 2, ('FF', 'HH'): 2, ('FF', 'KK'): 2, ('FF', 'LL'): 2, ('HH', 'KK'): 2, ('HH', 'LL'): 2})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if __name__ =='__main__' :\n",
    "\n",
    "    co_list = [ [\"AA | BB | CC | DD\",2019],\n",
    "                [\"EE | BB | FF \",2018],\n",
    "                [\"AA | GG | FF | HH | KK\",2019],\n",
    "                [\"CC | DD | FF | LL | AA\",2020],\n",
    "                [\"AA | BB | FF \",2017],\n",
    "                [\"EE | BB | GG \",2018],\n",
    "                [\"DD | GG | LL | HH | EE\",2019],\n",
    "                [\"AA | GG | CC | DD\",2018]]\n",
    "\n",
    "    # 获取节点列表\n",
    "    author_list = get_nodes(co_list,0) \n",
    "    # 合作网络（生成：合作矩阵，边-权重表，邻接表）\n",
    "    create_network(co_list,author_list,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('apple', 'banana'), ('banana', 'banana'), ('apple', 'banana')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import collections\n",
    "l = \"apple banana banana apple\".split()\n",
    "def pairwise(iterable):\n",
    "    \"\"\"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\"\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return ((a, b) if a < b else (b, a) for a, b in zip(a, b))\n",
    "list(pairwise(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('apple', 'banana'): 2, ('banana', 'banana'): 1})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(pairwise(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*-  coding: utf-8 -*-\n",
    "import os, sys\n",
    "import jieba, codecs, math\n",
    "import jieba.posseg as pseg\n",
    " \n",
    "names = {}            # 姓名字典\n",
    "relationships = {}    # 关系字典\n",
    "lineNames = []        # 每段内人物关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.load_userdict(\"E:\\ROST+系列人文社科研究大数据计算工具\\ROSTCM6\\dict.txt\")        # 加载字典\n",
    "with codecs.open(\"E:\\ROST+系列人文社科研究大数据计算工具\\ROSTCM6\\\\busan.txt\", \"r\", \"utf8\") as f:\n",
    "    for line in f.readlines():\n",
    "        poss = pseg.cut(line)        # 分词并返回该词词性\n",
    "        lineNames.append([])        # 为新读入的一段添加人物名称列表\n",
    "        for w in poss:\n",
    "            if w.flag != \"nr\" or len(w.word) < 2:\n",
    "                continue            # 当分词长度小于2或该词词性不为nr时认为该词不为人名\n",
    "            lineNames[-1].append(w.word)        # 为当前段的环境增加一个人物\n",
    "            if names.get(w.word) is None:\n",
    "                names[w.word] = 0\n",
    "                relationships[w.word] = {}\n",
    "            names[w.word] += 1                    # 该人物出现次数加 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc relations\n",
    "relations = {}\n",
    "f = (x for x in codecs.open(\"E:\\ROST+系列人文社科研究大数据计算工具\\ROSTCM6\\\\busan.txt\", 'r', 'utf-8'))\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    if not line: continue\n",
    "    segment = line.split('。')\n",
    "    for content in segment:\n",
    "        # put into set\n",
    "        relation = set()\n",
    "        for name in names:\n",
    "            if name in content: relation.add(name)\n",
    "        if len(relation) <= 1: continue\n",
    "        # process set to list\n",
    "        temp = []\n",
    "        for x in relation:\n",
    "            temp.append(x)\n",
    "        relation = temp\n",
    "        # process relations\n",
    "        for index, i in enumerate(relation):\n",
    "            for j in relation[index + 1:]:\n",
    "                key = str(i) + ' ' + str(j)\n",
    "                if not relations.get(key):\n",
    "                    relations[key] = 1\n",
    "                else:\n",
    "                    relations[key] += 1\n",
    "relations = sorted(relations.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('秀安 石宇', 53), ('尚华 石宇', 37), ('尚华 盛京', 19), ('石宇 盛京', 19), ('英国 石宇', 17), ('珍熙 英国', 15), ('秀安 盛京', 15), ('石宇的妈妈 石宇', 12), ('秀安 露宿者', 10), ('英国 尚华', 10), ('金代理 石宇', 6), ('秀安 尚华', 6), ('海英 少女', 6), ('海英 组长', 6), ('露宿者 石宇', 6), ('队员 珍熙', 5), ('露宿者 盛京', 5), ('金常务 列车长', 4), ('金常务 乘务长', 4), ('金常务 石宇', 4), ('石宇的妈妈 秀安', 3), ('海英 乘务长', 3), ('队员 英国', 3), ('金代理 组长', 3), ('秀安 金常务', 3), ('珍熙 乘务长', 3), ('卡住 尚华', 3), ('珍熙 金常务', 3), ('英国 金常务', 3), ('队员 少女', 2), ('少女 珍熙', 2), ('英国 珍熙', 2), ('组长 石宇', 2), ('卡住 石宇', 2), ('露宿者 尚华', 2), ('珍熙 石宇', 2), ('英国 秀安', 2), ('金常务 盛京', 2), ('金代理 安全性', 1), ('蓝天 乌云', 1), ('秀安 麻麻亮', 1), ('麻麻亮 石宇', 1), ('队员 美少女', 1), ('美少女 少女', 1), ('美少女 珍熙', 1), ('珍熙 谢谢', 1), ('海英 呼唤', 1), ('呼唤 少女', 1), ('海英 小姐', 1), ('组长 小姐', 1), ('英国 少女', 1), ('海英 石宇', 1), ('塞进 尚华', 1), ('盛京 安静', 1), ('盛京 谢谢', 1), ('明白 尚华', 1), ('明白 石宇', 1), ('游弋 露宿者', 1), ('列车长 乘务长', 1), ('爱抚 尚华', 1), ('爱抚 盛京', 1), ('冷笑 金常务', 1), ('珍熙 麻木', 1), ('石宇 尚华', 1), ('珍熙 呼唤', 1), ('英国 呼唤', 1), ('英国 露宿者', 1), ('金常务 钟吉', 1), ('珍熙 钟吉冲', 1), ('珍熙 钟吉', 1), ('钟吉冲 钟吉', 1), ('钟吉冲 乘务长', 1), ('钟吉 乘务长', 1), ('英国 盛京', 1), ('英国 拉进来', 1), ('秀安 拉进来', 1), ('金常务 拉进来', 1), ('石宇 拉进来', 1), ('盛京 拉进来', 1), ('幸存者 列车长', 1), ('秀安 苏醒过来', 1), ('石宇 苏醒过来', 1), ('石宇 露宿者', 1), ('盛京 苏醒过来', 1), ('盛京 露宿者', 1), ('苏醒过来 露宿者', 1), ('秀安 安抚', 1), ('石宇 安抚', 1), ('阿姨 秀安', 1), ('阿姨 石宇', 1), ('士兵 盛京', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "石宇 213\n",
      "金代理 15\n",
      "安全性 1\n",
      "秀安 135\n",
      "石宇的妈妈 12\n",
      "和娜英 2\n",
      "乌云 1\n",
      "蓝天 1\n",
      "黎明 15\n",
      "麻麻亮 1\n",
      "乘务长 15\n",
      "海英 25\n",
      "谢谢 3\n",
      "列车长 20\n",
      "安静 1\n",
      "美少女 1\n",
      "队员 10\n",
      "珍熙 48\n",
      "英国 60\n",
      "老婆婆 1\n",
      "钟吉 11\n",
      "组长 17\n",
      "少女 14\n",
      "金常务 52\n",
      "露宿者 22\n",
      "尚华 112\n",
      "呼唤 2\n",
      "小姐 2\n",
      "秀玉 1\n",
      "盛京 58\n",
      "塞进 1\n",
      "卡住 4\n",
      "游弋 4\n",
      "明白 2\n",
      "爱抚 1\n",
      "冷笑 1\n",
      "麻木 1\n",
      "钟吉冲 1\n",
      "拉进来 1\n",
      "幸存者 1\n",
      "苏醒过来 1\n",
      "安抚 1\n",
      "阿姨 1\n",
      "士兵 2\n"
     ]
    }
   ],
   "source": [
    "for name,times in names.items():\n",
    "    print (name, times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
